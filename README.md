# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run. In this project, we have tested the working of both Python SDK and Azure AutoML. 
The Azure SDK for Python is composed solely of over 180 individual Python libraries that relate to specific Azure services.
On the other Hand Azure AutoML is a no code solution which employ Azure's built-in capabilities for common machine learning tasks like 
classification, regression, and time-series forecasting

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
**Problem:**
We were given a dataset of Bank Marketing with primary task of binary classification. We have to clean and transform the dataset 
and employ both Python SDK and AutoML on it. The dataset provided had class imbalance as well and no missing values.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
**Solution:**
We have used in dataset on Python SDK and Azure AutoML. On Python SDK we used Logistic Regression with Choice on Hyper Params.
While on AutoML run, we have a greater choice of models. Logistic Regression had an accuracy of 0.91344 on Python SDK via HyperDrive
and best performing model was VotingEnsemble with accuracy of 0.9172 on Azure AutoMl run.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline consist of compute target created in Azure. a pyhton script (train.py for our case), Logistic Regression as the classification algorithm and inverse regulaization and mat_iteratons as hyper paramters

**What are the benefits of the parameter sampler you chose?**

**What are the benefits of the early stopping policy you chose?**

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML generated around 25 models for us and 4 of them outperform the Logistic Regression model from Scikit-learn pipeline. The best performing model was VotingEnsemble with accuracy of 0.9172. Hyperparameters generated were 'min_samples_leaf' ,  'min_samples_leaf' and 'n_estimators'. 

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
The biggest advantage AutoML has over Python SDk HyperDrive is that we dont need to code much and with a little efforts we have a variety of models ready with given performance metrics alongside doing the data drep tasks as well. On the contrary Python SDK Pipeline provide us with more customization in hyper paramters, data preperation and model selection while the amount of coding required here is time consuming but in some cases where advance feature engineering is required Scikit-learn pipeline can play a vital role. Another Solution would be first using AutoML to find the model comparision and then using Scikit learn pipeline with hyperdrive to further tune the model.
Here model from both pipeline performed almost equally with a slightly better results from AutoML run by VotingEnsemble model (also by LGBM) in comparision with Logistic Regression from Python SDK hyperdrive.

## Future work

Apart from checking high cardinality, checking for missing values and  class imbalance. I would like to see re-sampling techniques be added in AutoML to further improve model biases toward majority classes due to few data points/observation in minority classes. This will further strenghten the Fair AI policy also.
